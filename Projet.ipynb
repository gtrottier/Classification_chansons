{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amber-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import  matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import itertools\n",
    "from sklearn import metrics, pipeline, ensemble\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "directed-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('english_cleaned_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "innocent-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace = True)\n",
    "df.drop(columns='index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "administrative-favor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby how you doing You know I'm gonna cut r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin everything so easy it's like you seem s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search For tenderness It isn't hard to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I oh oh oh I If I wrote a book about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people the people the party it's pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218205</th>\n",
       "      <td>who-am-i-drinking-tonight</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I gotta say Boy after only just a couple of da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218206</th>\n",
       "      <td>liar</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I helped you find her diamond ring You made me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218207</th>\n",
       "      <td>last-supper</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>Look at the couple in the corner booth Looks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218208</th>\n",
       "      <td>christ-alone-live-in-studio</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>When I fly off this mortal earth And I'm measu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218209</th>\n",
       "      <td>amen</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I heard from a friend of a friend of a friend ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218210 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               song  year           artist    genre  \\\n",
       "0                         ego-remix  2009  beyonce-knowles      Pop   \n",
       "1                      then-tell-me  2009  beyonce-knowles      Pop   \n",
       "2                           honesty  2009  beyonce-knowles      Pop   \n",
       "3                   you-are-my-rock  2009  beyonce-knowles      Pop   \n",
       "4                     black-culture  2009  beyonce-knowles      Pop   \n",
       "...                             ...   ...              ...      ...   \n",
       "218205    who-am-i-drinking-tonight  2012       edens-edge  Country   \n",
       "218206                         liar  2012       edens-edge  Country   \n",
       "218207                  last-supper  2012       edens-edge  Country   \n",
       "218208  christ-alone-live-in-studio  2012       edens-edge  Country   \n",
       "218209                         amen  2012       edens-edge  Country   \n",
       "\n",
       "                                                   lyrics  \n",
       "0       Oh baby how you doing You know I'm gonna cut r...  \n",
       "1       playin everything so easy it's like you seem s...  \n",
       "2       If you search For tenderness It isn't hard to ...  \n",
       "3       Oh oh oh I oh oh oh I If I wrote a book about ...  \n",
       "4       Party the people the people the party it's pop...  \n",
       "...                                                   ...  \n",
       "218205  I gotta say Boy after only just a couple of da...  \n",
       "218206  I helped you find her diamond ring You made me...  \n",
       "218207  Look at the couple in the corner booth Looks a...  \n",
       "218208  When I fly off this mortal earth And I'm measu...  \n",
       "218209  I heard from a friend of a friend of a friend ...  \n",
       "\n",
       "[218210 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hidden-commissioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song      1\n",
       "year      0\n",
       "artist    0\n",
       "genre     0\n",
       "lyrics    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116724</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>booker-t-and-the-mg-s</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>All right people the rest of the hard working ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song  year                 artist genre  \\\n",
       "116724  NaN  2009  booker-t-and-the-mg-s  Jazz   \n",
       "\n",
       "                                                   lyrics  \n",
       "116724  All right people the rest of the hard working ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.isnull().sum())\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-warrior",
   "metadata": {},
   "source": [
    "Un seul NaN dans tout le tableau, on peut le drop sans aucun problème car nous avons beaucoup de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collectible-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index= 116724)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extreme-florence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Rock          100053\n",
       "Pop            34137\n",
       "Hip-Hop        22654\n",
       "Metal          21210\n",
       "Country        14158\n",
       "Jazz            7309\n",
       "Electronic      6942\n",
       "Other           3786\n",
       "R&B             3336\n",
       "Indie           2935\n",
       "Folk            1689\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.value_counts(df['genre']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-promotion",
   "metadata": {},
   "source": [
    "Le nombre de chansons des différents genres varie beaucoup, quelques uns en ont beaucoup plus que d'autres, particulièrement Rock.\n",
    "Si on entraîne un modèle sur ces données, on risquerait d'avoir un gros biais pour ces genres. On devrait donc rendre le set un peu plus 'équilibré'. Pour que ce soit réellement équilibré on doit perdre beaucoup d'entrées, mais j'espère que 1500 par genre reste assez.\n",
    "\n",
    "Pour rendre le tout plus rapide, on utilise temporairement(?) 15 de chaque genre. Sinon on aurait une sparse matrix énorme, plusieur milliers de colonnes. On pourra upscale plus tard et/ou travailler avec des one-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "western-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.groupby('genre').sample(1500, random_state = 42)\n",
    "#tout en minuscules\n",
    "df_sample['lyrics'] = df_sample['lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "saved-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mots inutiles/vides de sens et très communs\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "df_sample['tokenized'] = df_sample.apply(lambda row: nltk.word_tokenize(row['lyrics']), axis=1)\n",
    "df_sample['tokenized'] = df_sample['tokenized'].apply(lambda x : [word for word in x if (word not in stopwords and len(word) > 1  and word[0] != \"'\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funny-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On lemmatise puis prend le radical pour éviter les différentes formes conjuguées\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "def stem_text(text):\n",
    "    return [stemmer.stem(w) for w in text]\n",
    "def lemmatize_text(text):    \n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "df_sample['lemmatized'] = df_sample['tokenized'].apply(stem_text)\n",
    "df_sample['lemmatized'] = df_sample['lemmatized'].apply(lemmatize_text)\n",
    "df_sample.drop(columns=['tokenized'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dated-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "concrete-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"classifier=pipeline.Pipeline([\\n        ('tfidf_vectorizer', TfidfVectorizer(lowercase=False)),\\n        ('rf_classifier', ensemble.RandomForestClassifier(verbose=1,n_jobs=-1))]) #default 100 trees, peut tester 500\\n        \\n        \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"classifier=pipeline.Pipeline([\n",
    "        ('tfidf_vectorizer', TfidfVectorizer(lowercase=False)),\n",
    "        ('rf_classifier', ensemble.RandomForestClassifier(verbose=1,n_jobs=-1))]) #default 100 trees, peut tester 500\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "narrow-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(df_sample['lemmatized'], df_sample['genre'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-romantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "distributed-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-transmission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-galaxy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "forced-tuner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36746\n"
     ]
    }
   ],
   "source": [
    "words = df_sample['lemmatized'].values\n",
    "vocab = set(list(itertools.chain.from_iterable(words)))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conservative-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_str(text):\n",
    "    return ' '.join(e for e in text)\n",
    "df_sample['lemmas'] = df_sample['lemmatized'].apply(list_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chief-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_encodings = vectorizer.fit_transform(df_sample['lemmas'])\n",
    "df_sample['tfidf'] = list(tfidf_encodings.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "generic-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_for_training = np.array(df_sample['tfidf'].tolist()) #get the vectors back out of the dataframe for use in something else\n",
    "X_train, X_test,y_train, y_test = tts(vectors_for_training, df_sample['genre'].tolist(), test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "varied-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-growth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "front-multimedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "intellectual-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rocky-class",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3390909090909091"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "metrics.accuracy_score(y_test,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-strand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-witness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
